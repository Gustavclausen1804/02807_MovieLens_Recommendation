{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_movie_data = pd.read_csv('data/movies_with_tmdb_features_and_tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = final_movie_data[['movieId', 'title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the title, movieId, revenue and budget column\n",
    "final_movie_data = final_movie_data.drop([ 'spoken_languages', 'revenue', 'budget'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adventure' 'Animation' 'Children' 'Comedy' 'Fantasy' 'Romance' 'Drama'\n",
      " 'Action' 'Crime' 'Thriller' 'Horror' 'Mystery' 'Sci-Fi' 'IMAX'\n",
      " 'Documentary' 'War' 'Musical' 'Western' 'Film-Noir' '(no genres listed)']\n"
     ]
    }
   ],
   "source": [
    "unique_genres = final_movie_data['genres'].str.split('|').explode().unique()\n",
    "print(unique_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where countries is an empty list: 834\n",
      "Number of rows where countries is an empty list: 0\n"
     ]
    }
   ],
   "source": [
    "empty_rows_count = final_movie_data[final_movie_data['production_countries'] == '[]'].shape[0]\n",
    "print(f\"Number of rows where countries is an empty list: {empty_rows_count}\")\n",
    "\n",
    "\n",
    "final_movie_data = final_movie_data[final_movie_data['production_countries'].apply(lambda x: x != '[]')]\n",
    "\n",
    "# Reset index if needed\n",
    "final_movie_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "empty_rows_count = final_movie_data[final_movie_data['production_countries'] == '[]'].shape[0]\n",
    "print(f\"Number of rows where countries is an empty list: {empty_rows_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'tag' column contains 0 NaN values.\n"
     ]
    }
   ],
   "source": [
    "nan_count = final_movie_data['title'].isna().sum()\n",
    "print(f\"The 'tag' column contains {nan_count} NaN values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Lightweight and efficient\n",
    "\n",
    "\n",
    "embeddings = final_movie_data['title'].apply(lambda x: model.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   embeddings_1  embeddings_2  embeddings_3  embeddings_4  embeddings_5  \\\n",
      "0     -0.082835      0.053031      0.053576     -0.027935      0.016134   \n",
      "1     -0.105293      0.150841     -0.026398     -0.065596      0.006964   \n",
      "2     -0.098787      0.017650     -0.052744     -0.038677      0.069102   \n",
      "3     -0.087231      0.036612     -0.021703     -0.012105      0.062955   \n",
      "4     -0.069206      0.038752      0.014738      0.012141      0.050471   \n",
      "\n",
      "   embeddings_6  embeddings_7  embeddings_8  embeddings_9  embeddings_10  ...  \\\n",
      "0      0.012132      0.024147      0.020295     -0.005547       0.013974  ...   \n",
      "1      0.054954      0.052583      0.009236      0.014830      -0.011859  ...   \n",
      "2      0.000289      0.051787     -0.058244     -0.011713      -0.107212  ...   \n",
      "3      0.043525      0.013925     -0.055051      0.072511      -0.101182  ...   \n",
      "4      0.014589     -0.031408     -0.000894      0.046883      -0.006560  ...   \n",
      "\n",
      "   embeddings_375  embeddings_376  embeddings_377  embeddings_378  \\\n",
      "0        0.029772       -0.010131        0.007923       -0.047207   \n",
      "1       -0.029545        0.063663       -0.069504        0.070739   \n",
      "2       -0.059133       -0.007383       -0.020686        0.021802   \n",
      "3       -0.014956        0.082341       -0.064464        0.019814   \n",
      "4       -0.006111       -0.007785        0.041853        0.031688   \n",
      "\n",
      "   embeddings_379  embeddings_380  embeddings_381  embeddings_382  \\\n",
      "0       -0.060298        0.006076        0.002882        0.022616   \n",
      "1       -0.032337       -0.016868        0.107253        0.010561   \n",
      "2        0.003350       -0.027973        0.093832       -0.012006   \n",
      "3        0.013854        0.009431        0.029373       -0.006035   \n",
      "4        0.011167        0.049994        0.019151        0.037407   \n",
      "\n",
      "   embeddings_383  embeddings_384  \n",
      "0        0.053814        0.102970  \n",
      "1       -0.072631        0.008610  \n",
      "2        0.030255        0.000417  \n",
      "3       -0.024908        0.039693  \n",
      "4        0.075288       -0.041137  \n",
      "\n",
      "[5 rows x 384 columns]\n"
     ]
    }
   ],
   "source": [
    "embed_columns = [f'embeddings_{i+1}' for i in range(384)]\n",
    "\n",
    "embeddings_df = pd.DataFrame(embeddings.tolist(), index=final_movie_data.index, columns=embed_columns)\n",
    "\n",
    "print(embeddings_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25901, 20)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=20)\n",
    "\n",
    "pca_embeddings = pca.fit_transform(embeddings_df)\n",
    "\n",
    "print(pca_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_embeddings_df = pd.DataFrame(pca_embeddings, columns=[f'PC{i+1}' for i in range(pca_embeddings.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_movie_data = pd.concat([final_movie_data, pca_embeddings_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "country_to_continent = {\n",
    "    # North America\n",
    "    'United States of America': 'North America', 'Canada': 'North America', 'Mexico': 'North America', 'Bahamas': 'North America',\n",
    "    'Dominican Republic': 'North America', 'Cuba': 'North America', 'Puerto Rico': 'North America', \n",
    "    # South America\n",
    "    'Brazil': 'South America', 'Argentina': 'South America', 'Chile': 'South America', 'Peru': 'South America', \n",
    "    'Colombia': 'South America', 'Uruguay': 'South America', 'Venezuela': 'South America', 'Paraguay': 'South America', \n",
    "    # Europe\n",
    "    'Germany': 'Europe', 'United Kingdom': 'Europe', 'France': 'Europe', 'Italy': 'Europe', 'Spain': 'Europe', \n",
    "    'Netherlands': 'Europe', 'Belgium': 'Europe', 'Switzerland': 'Europe', 'Sweden': 'Europe', 'Portugal': 'Europe',\n",
    "    'Austria': 'Europe', 'Denmark': 'Europe', 'Ireland': 'Europe', 'Norway': 'Europe', 'Poland': 'Europe', \n",
    "    'Finland': 'Europe', 'Greece': 'Europe', 'Hungary': 'Europe', 'Czech Republic': 'Europe', 'Slovakia': 'Europe', \n",
    "    'Iceland': 'Europe', 'Russia': 'Europe', 'Serbia and Montenegro': 'Europe', 'Macedonia': 'Europe',\n",
    "    'Bulgaria': 'Europe', 'Yugoslavia': 'Europe', 'Luxembourg': 'Europe', 'Ukraine': 'Europe', 'Romania': 'Europe', \n",
    "    'Estonia': 'Europe', 'Lithuania': 'Europe', 'Albania': 'Europe', 'Latvia': 'Europe', 'Slovenia': 'Europe', \n",
    "    # Asia\n",
    "    'China': 'Asia', 'Japan': 'Asia', 'India': 'Asia', 'South Korea': 'Asia', 'Iran': 'Asia', 'Thailand': 'Asia', \n",
    "    'Hong Kong': 'Asia', 'Malaysia': 'Asia', 'Taiwan': 'Asia', 'Philippines': 'Asia', 'Turkey': 'Asia', 'Israel': 'Asia',\n",
    "    'Vietnam': 'Asia', 'Indonesia': 'Asia', 'Singapore': 'Asia', 'Jordan': 'Asia', 'Lebanon': 'Asia', \n",
    "    'Bangladesh': 'Asia', 'Pakistan': 'Asia', 'Sri Lanka': 'Asia', 'Saudi Arabia': 'Asia', 'Afghanistan': 'Asia', \n",
    "    'Kuwait': 'Asia', 'United Arab Emirates': 'Asia', 'Qatar': 'Asia', 'Myanmar': 'Asia', 'Kazakhstan': 'Asia', \n",
    "    # Africa\n",
    "    'South Africa': 'Africa', 'Egypt': 'Africa', 'Morocco': 'Africa', 'Tunisia': 'Africa', 'Algeria': 'Africa', \n",
    "    'Cameroon': 'Africa', 'Senegal': 'Africa', 'Burkina Faso': 'Africa', 'Zimbabwe': 'Africa', 'Ivory Coast': 'Africa', \n",
    "    'Libya': 'Africa', 'Nigeria': 'Africa', 'Kenya': 'Africa', 'Uganda': 'Africa', 'Angola': 'Africa', \n",
    "    'Mali': 'Africa', 'Niger': 'Africa', 'Ghana': 'Africa', 'Rwanda': 'Africa', 'Ethiopia': 'Africa', \n",
    "    # Oceania\n",
    "    'Australia': 'Oceania', 'New Zealand': 'Oceania', 'Papua New Guinea': 'Oceania', 'Solomon Islands': 'Oceania', \n",
    "    # For other countries not listed, include as needed\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "\n",
    "continents = ['North America', 'South America', 'Europe', 'Asia', 'Africa', 'Oceania']\n",
    "for continets in continents:\n",
    "    final_movie_data[continets] = 0\n",
    "\n",
    "for i, row in final_movie_data.iterrows():\n",
    "    countries = row['production_countries']\n",
    "    if isinstance(countries, str):\n",
    "        countries = ast.literal_eval(countries)\n",
    "    for country in countries:\n",
    "        continent = country_to_continent.get(country, None)\n",
    "\n",
    "        if continent: \n",
    "            final_movie_data.at[i, continent] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_movie_data = final_movie_data.drop(['production_countries'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the release_date to a numerical feature\n",
    "# We choose to convert the release date to a numerical feature represented by the months from the first movie's release date.\n",
    "# We made this decision instead of saving the dates as year and month column. \n",
    "# The reason is that we would like to capture the time difference between the movies rather than seasonal or yearly patterns.\n",
    "final_movie_data['release_date'] = pd.to_datetime(final_movie_data['release_date'])\n",
    "first_release_date = final_movie_data['release_date'].min()\n",
    "final_movie_data['release_date'] = (\n",
    "    (final_movie_data['release_date'].dt.year - first_release_date.year) * 12 +\n",
    "    (final_movie_data['release_date'].dt.month - first_release_date.month)\n",
    ")\n",
    "\n",
    "\n",
    "# hot-k encoding for 'genres' column\n",
    "# We felt that the genre feature was so important that we transformed it into a one-hot encoding format.\n",
    "# This way, we can use the genre information in the clustering process.\n",
    "# Step 1: Create a separate column for each genre\n",
    "for genre in unique_genres:\n",
    "    # Check if each genre is in the 'genre' column and create a binary column\n",
    "    final_movie_data[genre] = final_movie_data['genres'].apply(lambda x: 1 if genre in x.split('|') else 0)\n",
    "\n",
    "# Drop the original 'genre' column if needed\n",
    "final_movie_data = final_movie_data.drop(columns=['genres'])\n",
    "\n",
    "\n",
    "# We transformed the 'adult' column into a binary column.\n",
    "\n",
    "final_movie_data['adult'] = final_movie_data['adult'].apply(lambda x: 1 if x == 'True' else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the following features for clustering\n",
    "\n",
    "features = ['popularity', 'vote_average', 'vote_count', 'runtime',\n",
    "       'release_date', 'adult', 'PC1', 'PC2', 'PC3', 'PC4',\n",
    "       'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13',\n",
    "       'PC14', 'PC15', 'PC16', 'PC17', 'PC18', 'PC19', 'PC20', 'North America',\n",
    "       'South America', 'Europe', 'Asia', 'Africa', 'Oceania', 'Adventure',\n",
    "       'Animation', 'Children', 'Comedy', 'Fantasy', 'Romance', 'Drama',\n",
    "       'Action', 'Crime', 'Thriller', 'Horror', 'Mystery', 'Sci-Fi', 'IMAX',\n",
    "       'Documentary', 'War', 'Musical', 'Western', 'Film-Noir',\n",
    "       '(no genres listed)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will apply scaling to the features\n",
    "scaler = StandardScaler()\n",
    "final_movie_data_scaled = final_movie_data.copy()\n",
    "final_movie_data_scaled[features] = scaler.fit_transform(final_movie_data[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25901, 52)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "# Generate randomhow  data (100,000 vectors of dimension 128)\n",
    "print(final_movie_data_scaled[features].shape)\n",
    "# Build a flat index (exact nearest neighbors)\n",
    "d = final_movie_data_scaled[features].shape[1]\n",
    "index = faiss.IndexHNSWFlat(d, 5)\n",
    "index.hnsw.efConstruction = final_movie_data_scaled[features].shape[0]\n",
    "index.add(final_movie_data_scaled[features])  # Add vectors to the index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of nearest neighbors: [[ 2772   311   289 21207  1601   820]]\n",
      "Distances of nearest neighbors: [[ 0.       63.743866 67.50018  70.59146  81.06602  84.34573 ]]\n"
     ]
    }
   ],
   "source": [
    "# Query the index (find 5 nearest neighbors of the first vector)\n",
    "query = final_movie_data_scaled[final_movie_data_scaled['movieId'] == 2959][features]\n",
    "distances, indices = index.search(query, k=6)\n",
    "\n",
    "print(\"Indices of nearest neighbors:\", indices)\n",
    "print(\"Distances of nearest neighbors:\", distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292                   Pulp Fiction (1994)\n",
      "314      Shawshank Redemption, The (1994)\n",
      "833                 Godfather, The (1972)\n",
      "1636                       Titanic (1997)\n",
      "21813     Wolf of Wall Street, The (2013)\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "movieIds = final_movie_data.loc[indices[0]][\"movieId\"].values\n",
    "recommend_titles = movie_titles[movie_titles['movieId'].isin(movieIds[1:])][\"title\"]\n",
    "print(recommend_titles)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
